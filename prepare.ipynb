{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pretty_midi\n",
    "import pickle\n",
    "import numpy as np\n",
    "from intervaltree import IntervalTree\n",
    "\n",
    "midi_folder = 'midis'\n",
    "midi_list = os.listdir(midi_folder)\n",
    "\n",
    "data = []\n",
    "durations = []\n",
    "basic_beat = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_dur(durations,dur):\n",
    "    flag = False\n",
    "    for duration in durations:\n",
    "        if abs(duration - dur)<=0.25:\n",
    "            flag = True\n",
    "            return duration,flag   \n",
    "    return dur,flag\n",
    "\n",
    "def read_note_sequence(midi_list):\n",
    "    note_seq = []\n",
    "    print(\"Please wait, this will takes a while\")\n",
    "    for i,dir in enumerate(midi_list):\n",
    "        midi_path = os.path.join(midi_folder,dir)\n",
    "\n",
    "        midi = pretty_midi.PrettyMIDI(midi_path)\n",
    "        assert len(midi.instruments)==1\n",
    "        notes = midi.instruments[0].notes\n",
    "        note_seq.append((0,0,0,\"|start|\"))\n",
    "        for note in notes:\n",
    "            start = float(format(note.start,'.1f'))\n",
    "            end = float(format(note.end,'.1f'))\n",
    "            dur = float(format(end-start,'.1f'))\n",
    "            if start==end:\n",
    "                continue\n",
    "            else:\n",
    "                note_seq.append((dur,start,end,note.pitch))\n",
    "        note_seq.append((0,end,end,\"|end|\"))\n",
    "    return note_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait, this will takes a while\n"
     ]
    }
   ],
   "source": [
    "note_seq = read_note_sequence(midi_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(ids, counts=None):\n",
    "    \"\"\"\n",
    "    Given a list of integers, return a dictionary of counts of consecutive pairs\n",
    "    Example: [1, 2, 3, 1, 2] -> {(1, 2): 2, (2, 3): 1, (3, 1): 1}\n",
    "    Optionally allows to update an existing dictionary of counts\n",
    "    \"\"\"\n",
    "    counts = {} if counts is None else counts\n",
    "    for pair in zip(ids, ids[1:]): # iterate consecutive elements\n",
    "        counts[pair] = counts.get(pair, 0) + 1\n",
    "    return counts\n",
    "\n",
    "\n",
    "def merge(ids, pair, idx):\n",
    "    \"\"\"\n",
    "    In the list of integers (ids), replace all consecutive occurrences\n",
    "    of pair with the new integer token idx\n",
    "    Example: ids=[1, 2, 3, 1, 2], pair=(1, 2), idx=4 -> [4, 3, 4]\n",
    "    \"\"\"\n",
    "    newids = []\n",
    "    i = 0\n",
    "    while i < len(ids):\n",
    "        # if not at the very last position AND the pair matches, replace it\n",
    "        if ids[i] == pair[0] and i < len(ids) - 1 and ids[i+1] == pair[1]:\n",
    "            newids.append(idx)\n",
    "            i += 2\n",
    "        else:\n",
    "            newids.append(ids[i])\n",
    "            i += 1\n",
    "    return newids\n",
    "\n",
    "def render_token(t: bytes) -> str:\n",
    "    # pretty print a token, escaping control characters\n",
    "    s = t.decode('utf-8', errors='replace')\n",
    "    return s\n",
    "\n",
    "class Tokenizer:\n",
    "    \"\"\"Base class for Tokenizers\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # default: vocab size of 256 (all bytes), no merges, no patterns\n",
    "        self.merges = {} # (int, int) -> int\n",
    "        self.pattern = \"\" # str\n",
    "        self.special_tokens = {} # str -> int, e.g. {'<|endoftext|>': 100257}\n",
    "        self.vocab = self._build_vocab() # int -> bytes\n",
    "\n",
    "    def train(self, text, vocab_size, verbose=False):\n",
    "        # Tokenizer can train a vocabulary of size vocab_size from text\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def encode(self, text):\n",
    "        # Tokenizer can encode a string into a list of integers\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def decode(self, ids):\n",
    "        # Tokenizer can decode a list of integers into a string\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _build_vocab(self):\n",
    "        # vocab is simply and deterministically derived from merges\n",
    "        vocab = {idx: bytes([idx]) for idx in range(256)}\n",
    "        for (p0, p1), idx in self.merges.items():\n",
    "            vocab[idx] = vocab[p0] + vocab[p1]\n",
    "        for special, idx in self.special_tokens.items():\n",
    "            vocab[idx] = special.encode(\"utf-8\")\n",
    "        return vocab\n",
    "\n",
    "    def save(self, file_prefix):\n",
    "        \"\"\"\n",
    "        Saves two files: file_prefix.vocab and file_prefix.model\n",
    "        This is inspired (but not equivalent to!) sentencepiece's model saving:\n",
    "        - model file is the critical one, intended for load()\n",
    "        - vocab file is just a pretty printed version for human inspection only\n",
    "        \"\"\"\n",
    "        # write the model: to be used in load() later\n",
    "        model_file = file_prefix + \".model\"\n",
    "        with open(model_file, 'w') as f:\n",
    "            # write the version, pattern and merges, that's all that's needed\n",
    "            f.write(\"minbpe v1\\n\")\n",
    "            f.write(f\"{self.pattern}\\n\")\n",
    "            # write the special tokens, first the number of them, then each one\n",
    "            f.write(f\"{len(self.special_tokens)}\\n\")\n",
    "            for special, idx in self.special_tokens.items():\n",
    "                f.write(f\"{special} {idx}\\n\")\n",
    "            # the merges dict\n",
    "            for idx1, idx2 in self.merges:\n",
    "                f.write(f\"{idx1} {idx2}\\n\")\n",
    "        # write the vocab: for the human to look at\n",
    "        vocab_file = file_prefix + \".vocab\"\n",
    "        inverted_merges = {idx: pair for pair, idx in self.merges.items()}\n",
    "        with open(vocab_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            for idx, token in self.vocab.items():\n",
    "                # note: many tokens may be partial utf-8 sequences\n",
    "                # and cannot be decoded into valid strings. Here we're using\n",
    "                # errors='replace' to replace them with the replacement char ï¿½.\n",
    "                # this also means that we couldn't possibly use .vocab in load()\n",
    "                # because decoding in this way is a lossy operation!\n",
    "                s = render_token(token)\n",
    "                # find the children of this token, if any\n",
    "                if idx in inverted_merges:\n",
    "                    # if this token has children, render it nicely as a merge\n",
    "                    idx0, idx1 = inverted_merges[idx]\n",
    "                    s0 = render_token(self.vocab[idx0])\n",
    "                    s1 = render_token(self.vocab[idx1])\n",
    "                    f.write(f\"[{s0}][{s1}] -> [{s}] {idx}\\n\")\n",
    "                else:\n",
    "                    # otherwise this is leaf token, just print it\n",
    "                    # (this should just be the first 256 tokens, the bytes)\n",
    "                    f.write(f\"[{s}] {idx}\\n\")\n",
    "\n",
    "    def load(self, model_file):\n",
    "        \"\"\"Inverse of save() but only for the model file\"\"\"\n",
    "        assert model_file.endswith(\".model\")\n",
    "        # read the model file\n",
    "        merges = {}\n",
    "        special_tokens = {}\n",
    "        idx = 256\n",
    "        with open(model_file, 'r', encoding=\"utf-8\") as f:\n",
    "            # read the version\n",
    "            version = f.readline().strip()\n",
    "            assert version == \"minbpe v1\"\n",
    "            # read the pattern\n",
    "            self.pattern = f.readline().strip()\n",
    "            # read the special tokens\n",
    "            num_special = int(f.readline().strip())\n",
    "            for _ in range(num_special):\n",
    "                special, special_idx = f.readline().strip().split()\n",
    "                special_tokens[special] = int(special_idx)\n",
    "            # read the merges\n",
    "            for line in f:\n",
    "                idx1, idx2 = map(int, line.split())\n",
    "                merges[(idx1, idx2)] = idx\n",
    "                idx += 1\n",
    "        self.merges = merges\n",
    "        self.special_tokens = special_tokens\n",
    "        self.vocab = self._build_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicTokenizer(Tokenizer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def train(self, text, vocab_size, verbose=False):\n",
    "        assert vocab_size >= 4879\n",
    "        num_merges = vocab_size - 4879\n",
    "\n",
    "        # input text preprocessing\n",
    "        ids = text # list of integers in range 0..255\n",
    "\n",
    "        # iteratively merge the most common pairs to create new tokens\n",
    "        merges = {} # (int, int) -> int\n",
    "        vocab = {idx: bytes([idx]) for idx in range(4879)} # int -> bytes\n",
    "        for i in range(num_merges):\n",
    "            # count up the number of times every consecutive pair appears\n",
    "            stats = get_stats(ids)\n",
    "            # find the pair with the highest count\n",
    "            pair = max(stats, key=stats.get)\n",
    "            # mint a new token: assign it the next available id\n",
    "            idx = 4879 + i\n",
    "            # replace all occurrences of pair in ids with idx\n",
    "            ids = merge(ids, pair, idx)\n",
    "            # save the merge\n",
    "            merges[pair] = idx\n",
    "            vocab[idx] = vocab[pair[0]] + vocab[pair[1]]\n",
    "            # prints\n",
    "            if verbose:\n",
    "                print(f\"merge {i+1}/{num_merges}: {pair} -> {idx} ({vocab[idx]}) had {stats[pair]} occurrences\")\n",
    "\n",
    "        # save class variables\n",
    "        self.merges = merges # used in encode()\n",
    "        self.vocab = vocab   # used in decode()\n",
    "\n",
    "    def decode(self, ids):\n",
    "        # given ids (list of integers), return Python string\n",
    "        text_bytes = b\"\".join(self.vocab[idx] for idx in ids)\n",
    "        text = text_bytes.decode(\"utf-8\", errors=\"replace\")\n",
    "        return text\n",
    "\n",
    "    def encode(self, text):\n",
    "        # given a string text, return the token ids\n",
    "        text_bytes = text.encode(\"utf-8\") # raw bytes\n",
    "        ids = list(text_bytes) # list of integers in range 0..255\n",
    "        while len(ids) >= 2:\n",
    "            # find the pair with the lowest merge index\n",
    "            stats = get_stats(ids)\n",
    "            pair = min(stats, key=lambda p: self.merges.get(p, float(\"inf\")))\n",
    "            # subtle: if there are no more merges available, the key will\n",
    "            # result in an inf for every single pair, and the min will be\n",
    "            # just the first pair in the list, arbitrarily\n",
    "            # we can detect this terminating case by a membership check\n",
    "            if pair not in self.merges:\n",
    "                break # nothing else can be merged anymore\n",
    "            # otherwise let's merge the best pair (lowest merge index)\n",
    "            idx = self.merges[pair]\n",
    "            ids = merge(ids, pair, idx)\n",
    "        return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bytes must be in range(0, 256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tokenizer \u001b[39m=\u001b[39m BasicTokenizer()\n\u001b[0;32m----> 2\u001b[0m tokenizer\u001b[39m.\u001b[39;49mtrain(note_seq,\u001b[39m5000\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[36], line 15\u001b[0m, in \u001b[0;36mBasicTokenizer.train\u001b[0;34m(self, text, vocab_size, verbose)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# iteratively merge the most common pairs to create new tokens\u001b[39;00m\n\u001b[1;32m     14\u001b[0m merges \u001b[39m=\u001b[39m {} \u001b[39m# (int, int) -> int\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m vocab \u001b[39m=\u001b[39m {idx: \u001b[39mbytes\u001b[39m([idx]) \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m4879\u001b[39m)} \u001b[39m# int -> bytes\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_merges):\n\u001b[1;32m     17\u001b[0m     \u001b[39m# count up the number of times every consecutive pair appears\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     stats \u001b[39m=\u001b[39m get_stats(ids)\n",
      "Cell \u001b[0;32mIn[36], line 15\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# iteratively merge the most common pairs to create new tokens\u001b[39;00m\n\u001b[1;32m     14\u001b[0m merges \u001b[39m=\u001b[39m {} \u001b[39m# (int, int) -> int\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m vocab \u001b[39m=\u001b[39m {idx: \u001b[39mbytes\u001b[39;49m([idx]) \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m4879\u001b[39m)} \u001b[39m# int -> bytes\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_merges):\n\u001b[1;32m     17\u001b[0m     \u001b[39m# count up the number of times every consecutive pair appears\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     stats \u001b[39m=\u001b[39m get_stats(ids)\n",
      "\u001b[0;31mValueError\u001b[0m: bytes must be in range(0, 256)"
     ]
    }
   ],
   "source": [
    "tokenizer = BasicTokenizer()\n",
    "tokenizer.train(note_seq,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100_0.1', '100_0.2', '100_0.3', '100_0.4', '100_0.5', '100_0.6', '100_0.7', '100_0.8', '100_0.9', '100_1.0']\n",
      "vocab size is 4879\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "# note_seq.sort(key= lambda s:s[1])\n",
    "# print(note_seq[:50])\n",
    "for note in note_seq:\n",
    "    data.append(str(note[-1])+'_'+str(note[0]))\n",
    "chars = sorted(list(set(data)))\n",
    "print(chars[:10])\n",
    "print(\"vocab size is {}\".format(len(chars)))\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "def encode(s):\n",
    "    return [stoi[c] for c in s] # encoder: take a list of string, output a list of integers\n",
    "def decode(l):\n",
    "    return [itos[i] for i in l] # decoder: take a list of integers, output list of string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train has 1,637,512 tokens\n",
      "val has 181,946 tokens\n"
     ]
    }
   ],
   "source": [
    "n = len(data)\n",
    "train_data = data[:int(n*0.9)]\n",
    "val_data = data[int(n*0.9):]\n",
    "\n",
    "# encode both to integers\n",
    "train_ids = encode(train_data)\n",
    "val_ids = encode(val_data)\n",
    "print(f\"train has {len(train_ids):,} tokens\")\n",
    "print(f\"val has {len(val_ids):,} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to bin files\n",
    "train_ids = np.array(train_ids).astype(np.uint16)\n",
    "val_ids = np.array(val_ids).astype(np.uint16)\n",
    "train_ids.tofile(os.path.join(os.path.abspath(''), 'train.bin'))\n",
    "val_ids.tofile(os.path.join(os.path.abspath(''), 'val.bin'))\n",
    "\n",
    "# save the meta information as well, to help us encode/decode later\n",
    "meta = {\n",
    "    'vocab_size': vocab_size,\n",
    "    'itos': itos,\n",
    "    'stoi': stoi,\n",
    "}\n",
    "with open(os.path.join(os.path.abspath(''), 'meta.pkl'), 'wb') as f:\n",
    "    pickle.dump(meta, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div id=\"midiPlayerDiv15310\"></div>\n",
       "        <link rel=\"stylesheet\" href=\"https://cuthbertLab.github.io/music21j/css/m21.css\">\n",
       "        \n",
       "        <script\n",
       "        src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"\n",
       "        ></script>\n",
       "    \n",
       "        <script>\n",
       "        function midiPlayerDiv15310_play() {\n",
       "            const rq = require.config({\n",
       "                paths: {\n",
       "                    'music21': 'https://cuthbertLab.github.io/music21j/releases/music21.debug',\n",
       "                }\n",
       "            });\n",
       "            rq(['music21'], function(music21) {\n",
       "                mp = new music21.miditools.MidiPlayer();\n",
       "                mp.addPlayer(\"#midiPlayerDiv15310\");\n",
       "                mp.base64Load(\"data:audio/midi;base64,TVRoZAAAAAYAAQACJ2BNVHJrAAAAFAD/UQMHoSAA/1gEBAIYCM5g/y8ATVRyawAAA9cA/wMFUGlhbm8AwAAA4ABAAMAAzmCQP2SBiWiAPwAAkDZk9hCANgAAkD9koGiQQmSGSIA/APxYkEtkhkiAQgCBgyCASwCNEJBCZIGkCJBLZI0QgEIArXiASwCNEJA5ZLsIgDkAAJBFZLsIgEUAAJBLZLsIgEsAjRCQRWS0QJBLZIZIgEUAtECASwCNEJBCZLsIgEIAAJBOZOI4gE4AAJA/ZNUokEVkjRCAPwCteIBFAI0QkEhkuwiASAAAkEtkuwiASwAAkD9kuwiAPwCNEJBLZLRAkD9khkiASwC0QIA/AI0QkEJkuwiAQgAAkD9kuwiAPwAAkEtkuwiASwCNEJBIZLRAkD9khkiASAC0QIA/AI0QkEJkuwiAQgAAkEtkuwiASwAAkEhkuwiASACNEJBUZLRAkFRkhkiAVAC0QIBUAI0QkD9kuwiAPwAAkEVkuwiARQAAkD9kuwiAPwCNEJBCZLRAkEtkhkiAQgC0QIBLAI0QkDxkpzCQP2SNEIA8AKBokD9khkiAPwCteIA/AACQQmS0QIBCAACQP2SteJBCZIZIgD8AoGiQP2SNEIBCAKBokEhkhkiAPwCteIBIAACQS2S7CIBLAACQP2S7CIA/AI0QkEJkmiCAQgAAkD9kmiCAPwAAkEhkuwiASACNEJBOZLsIgE4AAJA8ZLsIgDwAAJBIZLsIgEgAjRCQUWSteJBUZIZIgFEAtECAVAAAkEJkuwiAQgAAkERkuwiARACNEJBCZLRAkD9khkiAQgC0QIA/AI0QkFNkuwiAUwAAkERkuwiARAAAkE5kuwiATgCNEJA/ZLRAkEJkhkiAPwC0QIBCAI0QkEVkuwiARQAAkFBkzmCAUAAAkEhkzmCASAAAkE5k6QCATgAAkEhkuwiASACNEJBLZIGkCJBCZI0QgEsApzCAQgAAkEtkuwiASwAAkEJkuwiAQgCNEJBFZLRAkD9khkiARQC0QIA/AI0QkEJkuwiAQgAAkFRkuwiAVAAAkE1kgZ1AgE0AAJBIZLsIgEgAjRCQS2TOYIBLAACQUWTpAIBRAACQS2TpAIBLAACQP2S7CIA/AI0QkEJkuwiAQgAAkEtkuwiASwAAkEhkuwiASACNEJA8ZLRAkD9khkiAPAC0QIA/AI0QkEJkuwiAQgAAkEVkuwiARQAAkEtkuwiASwCNEJA8ZLRAkD9khkiAPAC0QIA/AI0QkDxkuwiAPAAAkEJkuwiAQgAAkD9kuwiAPwCNEJBIZLRAkFFkhkiASAC0QIBRAI0QkFRkuwiAVAAAkEhkuwiASAAAkEhkuwiASADOYP8vAA==\");\n",
       "            });\n",
       "        }\n",
       "        if (typeof require === 'undefined') {\n",
       "            setTimeout(midiPlayerDiv15310_play, 2000);\n",
       "        } else {\n",
       "            midiPlayerDiv15310_play();\n",
       "        }\n",
       "        </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div id=\"midiPlayerDiv18115\"></div>\n",
       "        <link rel=\"stylesheet\" href=\"https://cuthbertLab.github.io/music21j/css/m21.css\">\n",
       "        \n",
       "        <script\n",
       "        src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"\n",
       "        ></script>\n",
       "    \n",
       "        <script>\n",
       "        function midiPlayerDiv18115_play() {\n",
       "            const rq = require.config({\n",
       "                paths: {\n",
       "                    'music21': 'https://cuthbertLab.github.io/music21j/releases/music21.debug',\n",
       "                }\n",
       "            });\n",
       "            rq(['music21'], function(music21) {\n",
       "                mp = new music21.miditools.MidiPlayer();\n",
       "                mp.addPlayer(\"#midiPlayerDiv18115\");\n",
       "                mp.base64Load(\"data:audio/midi;base64,TVRoZAAAAAYAAQACJ2BNVHJrAAAAFAD/UQMHoSAA/1gEBAIYCM5g/y8ATVRyawAAA8wA/wMFUGlhbm8AwAAA4ABAAMAAzmCQTGQAkE5kmiCATAAAgE4AAJA5ZOkAgDkAAJBJZJoggEkAAJBAZIGDIIBAAACQLWT8WJBJZIZIgC0AzmCQTGSNEIBJANtwgEwAAJBJZK14kDlkhkiASQCBgyCAOQAAkExktECATAAAkElkrXiQTGSGSIBJAIGDIIBMAACQSmSaIIBKAACQSWSgaJBJZIZIgEkAjRCASQAAkEpkmiCASgAAkElktECASQAAkExktECATAAAkEpkhkiQSWSNEIBKAKBokEdkhkiASQCaIJBJZIZIgEcAoGiASQAAkExkzmCATAAAkElkpzCQR2SNEIBJAJoggEcAAJBJZKcwkEdkjRCASQDBUIBHAACQSmS7CIBKAI0QkElkrXiQR2SGSIBJAJogkElkhkiARwCnMJBEZIZIgEkAmiCQR2SGSIBEAJNYgEcAAJBJZLRAgEkAAJBJZACQSWSaIIBJAACASQAAkEdkmiCARwAAkERkoGiQSWSGSIBEAO9IgEkAAJBFZPYQkEtkjRCARQDvSJBHZIZIgEsA/FiARwAAkElktECASQAAkEdk1SiQR2SNEIBHAKBokElkhkiARwCaIJBRZIZIgEkA9hCQUGSGSIBRAJogkFNkhkiAUACgaIBTAACQUGSgaJBJZIZIgFAAyBiASQAAkFNkmiCAUwAAkEJkgYMggEIAAJBQZLRAkEdkhkiAUADIGIBHAACQTGSBgyCATAAAkEVk4jiARQAAkFFkuwiAUQAAkFBkuwiAUAAAkE5kuwiATgCNEJBRZLRAkFNkhkiAUQD8WIBTAACQVmTpAIBWAACQUGS7CIBQAI0QkFFk9hCQUGSNEIBRAK14gFAAjRCQTGTpAIBMAACQWGTpAIBYAACQSmS7CIBKAI0QkFhkgYlogFgAAJBOZOkAgE4AAJBJZLsIgEkAjRCQTGTOYIBMAACQSmSgaJBHZIZIgEoAAJBJZI0QgEcAmiCASQAAkEpkoGiQTGSGSIBKAK14kFNkhkiATAD8WIBTAACQRWSaIIBFAACQR2S7CIBHAI0QkExkoGiQRWSGSIBMAJNYgEUAAJBJZLsIgEkAAJBFZKcwgEUAAJBJZKBokEpkhkiASQCTWIBKAACQR2S7CIBHAACQTGS7CIBMAI0QkEVkmiCARQAAkElkmiCASQAAkEVkoGiQR2SGSIBFAKcwkElkhkiARwCaIJBKZIZIgEkA23CASgAAkElkuwiASQAAkEVkpzCARQAAkEVkoGiQR2SGSIBFALRAgEcAzmD/LwA=\");\n",
       "            });\n",
       "        }\n",
       "        if (typeof require === 'undefined') {\n",
       "            setTimeout(midiPlayerDiv18115_play, 2000);\n",
       "        } else {\n",
       "            midiPlayerDiv18115_play();\n",
       "        }\n",
       "        </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div id=\"midiPlayerDiv20075\"></div>\n",
       "        <link rel=\"stylesheet\" href=\"https://cuthbertLab.github.io/music21j/css/m21.css\">\n",
       "        \n",
       "        <script\n",
       "        src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"\n",
       "        ></script>\n",
       "    \n",
       "        <script>\n",
       "        function midiPlayerDiv20075_play() {\n",
       "            const rq = require.config({\n",
       "                paths: {\n",
       "                    'music21': 'https://cuthbertLab.github.io/music21j/releases/music21.debug',\n",
       "                }\n",
       "            });\n",
       "            rq(['music21'], function(music21) {\n",
       "                mp = new music21.miditools.MidiPlayer();\n",
       "                mp.addPlayer(\"#midiPlayerDiv20075\");\n",
       "                mp.base64Load(\"data:audio/midi;base64,TVRoZAAAAAYAAQACJ2BNVHJrAAAAFAD/UQMHoSAA/1gEBAIYCM5g/y8ATVRyawAAA9YA/wMFUGlhbm8AwAAA4ABAAMAAzmCQQ2TOYIBDAACQQGSaIIBAAACQTGS7CIBMAI0QkDxkzmCAPAAAkEJkpzCQR2SNEIBCAOkAgEcAAJBDZPYQkExkjRCAQwDvSJBHZIZIgEwArXiARwAAkD5k6QCAPgAAkCtk70iQR2SGSIArAO9IgEcAAJBKZO9IkD5khkiASgDIGIA+AACQQ2TOYIBDAACQO2TpAIA7AACQPmTpAIA+AACQR2SBgyCARwAAkEhkgYMggEgAAJBHZLRAkEpkhkiARwC0QIBKAI0QkEFkpzCQPmSNEIBBAK14gD4AjRCQT2S0QJBCZIZIgE8AtECAQgCNEJBDZLsIgEMAAJBKZLsIgEoAAJBPZLsIgE8AjRCQQmSaIIBCAACQPmS7CIA+AACQQ2S7CIBDAI0QkD5ktECQQ2SGSIA+ALRAgEMAjRCQPmS7CIA+AACQO2S7CIA7AACQQ2S7CIBDAI0QkEdktECQSmSGSIBHAK14gEoAAJA+ZLRAgD4AAJBDZLRAkEdkhkiAQwC0QIBHAI0QkEpk70iQO2SGSIBKAPYQkENkhkiAOwC0QIBDAACQT2S7CIBPAACQPmTiOIA+AACQQGTiOIBAAACQQ2TVKJBPZI0QgEMA23CATwAAkEdk6QCARwAAkD5k6QCAPgAAkEdkuwiARwCNEJA+ZLsIgD4AAJBPZLsIgE8AAJBDZLsIgEMAjRCQSmS0QJBDZIZIgEoAtECAQwCNEJBHZO9IkENkhkiARwDIGIBDAACQSmS0QJBDZIZIgEoA/FiAQwAAkDtkgYMggDsAAJBDZK14kEBkhkiAQwCgaJA8ZI0QgEAAoGiQPmSGSIA8AK14gD4AAJA3ZIGDIIA3AACQT2S0QJBHZIZIgE8AtECARwCNEJA+ZO9IkE1khkiAPgDiOIBNAACQT2TpAIBPAACQO2S7CIA7AI0QkEFkuwiAQQAAkDlkuwiAOQAAkD5kuwiAPgCNEJBBZLRAkENkhkiAQQC0QIBDAI0QkEFkuwiAQQAAkEVkuwiARQAAkD5kzmCAPgAAkEpkzmCASgAAkDdk/FiQPmSGSIA3APxYgD4AAJA1ZIGDIIA1AACQQ2TOYIBDAACQRWSBgyCQQWSGSIBFAPxYgEEAAJBKZIGDIIBKAACQTWT8WJBKZIZIgE0A70iQPmSNEIBKAO9IkEdkhkiAPgC0QIBHAI0QkD5k9hCQQWSNEIA+AO9IkE1khkiAQQD8WIBNAACQPGSBgyCAPAAAkENk/FiQR2SGSIBDAIGDIIBHAACQQ2S7CIBDAM5g/y8A\");\n",
       "            });\n",
       "        }\n",
       "        if (typeof require === 'undefined') {\n",
       "            setTimeout(midiPlayerDiv20075_play, 2000);\n",
       "        } else {\n",
       "            midiPlayerDiv20075_play();\n",
       "        }\n",
       "        </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from music21 import midi\n",
    "def playMidi(path):\n",
    "  mf = midi.MidiFile()\n",
    "  mf.open(path) # path='abc.midi'\n",
    "  mf.read()\n",
    "  mf.close()\n",
    "  s = midi.translate.midiFileToStream(mf)\n",
    "  s.show('midi')\n",
    "for midi_file in os.listdir(os.path.join(os.path.abspath(''),'out-shakespeare-char'))[:3]:\n",
    "  playMidi(os.path.join(os.path.abspath(''),'out-shakespeare-char',midi_file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('Test': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d380874e6299c4d76594d86252f948ba21a17f8127c9a1a4ddcbf08c9dab5d65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
